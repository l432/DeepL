

%\documentclass[aip,reprint]{revtex4-1}
%\documentclass[sn-mathphys]{sn-jnl}
\documentclass[10pt]{iopart}
%\documentclass[aip,jap,preprint]{revtex4-1}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}
\usepackage{color}
\usepackage{color,soul}
\usepackage{url}
\usepackage{makecell}
%\draft % marks overfull lines with a black rule on the right

\begin{document}

Dear Editor and Reviewers,

We sincerely thank you for taking the time to review our manuscript
``Computer vision-based method for quantifying iron-related defects in silicon solar cells''
(Ref. No.: SST--111269).
Your insightful comments and constructive suggestions have greatly helped us improve
the quality of our work.
We particularly appreciate your careful reading and thoughtful feedback,
which have led to significant improvements in both the technical content and presentation clarity of our manuscript.
We have carefully addressed all the comments and made corresponding revisions to the manuscript.
The location of revisions is pointed by red color and highlighted in yellow in ``CompleteDocumentForReview.pdf''.
Below we provide our detailed point-by-point responses to each comment.
We hope the revised manuscript better meets your expectations and standards for publication in Solar Energy.



\subsection*{Response to Reviewer \#1 }

\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~1.}}
\emph{Novelty and Contribution:
The idea of applying pre-trained CV models to wavelet-transformed kinetic data is interesting and potentially generalizable.
However, similar signal-to-image ML transformations exist in other domains.
The manuscript should emphasize what new physical or methodological insight this work provides beyond prior
Fourier/wavelet-based ML approaches..}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We thank the Reviewer for this insightful comment.

To summarize the novelty and contribution of our work, as well as
its distinction from previous studies on semiconductor defects, we note the following.
The use of CNNs for analysing defect-related electrophysical dependencies has been explored previously \cite{Buratti2022}.
In that study, however, image construction required a set of curves measured under different conditions,
specifically at various temperatures, and the model was trained from scratch, which demanded a very large training dataset.
In contrast, our approach relies on a single kinetic dependency and leverages the capabilities of pre-trained computer vision (CV) models.
Standard CV models for defect detection in solar cells have also been reported \cite{Liu2024a, Li2024a, Jia2024, Otamendi2021, Chen2022, AlOtum2024, Abdelsattar2025, tella2025},
although prior work focused on macro-defects and processed naturally acquired images from conventional cameras.
In our case, the emphasis is on point-defect characteristics, and the images used as input are generated from electrophysical measurements.
In the analysis of solar cells, wavelet transforms have been applied to one-dimensional dependencies \cite{Vinit2020}
in addition to their use in improving defect detection in photographic images \cite{Li2012}.
In those studies, however, the resulting wavelet coefficients were used as features in regression algorithms
rather than for constructing images, which is the approach adopted in the present work.
More broadly, to the best of our knowledge, one-dimensional signal-to-image conversion for CNN input preparation has typically been achieved
either by employing a set of curves \cite{Buratti2022} or by digitizing standard graphs produced in software such as Origin \cite{Held2024}.
The use of the wavelet transform as a preprocessing step for CNNs is therefore novel.
Finally, our methodology is designed to function effectively with extremely small datasets,
which facilitates the practical application of the proposed approach.

This information has been added to the revised manuscript in the final paragraph of the Introduction.

\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~2.}}
\emph{Dataset Size and Overfitting Risk:
The study relies on extremely small datasets (25 simulated and 28 experimental samples).
Although data augmentation is performed, flipping or rotating spectrograms likely introduces redundant samples rather
than independent data points.
The near-perfect $R^2$ values (0.996–0.999) strongly suggest overfitting.
A robust cross-validation (e.g., k-fold or leave-one-out) with uncertainty quantification is needed.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}

The minimal level shift, which was used as evidence of defect transformation, was 40~meV.





\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~3.}}
\emph{Simulation–Experiment Gap:
A major discrepancy is observed between simulated
and experimental predictions, requiring a post-hoc quadratic correction.
This implies that the CNN–regressor models primarily learn the synthetic data distribution rather
than physical correlations.
The authors should explore physics-based domain adaptation or partial fine-tuning using experimental data instead of empirical correction.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


The description of observation technique was modified
(page~3, left column, paragraph~3)



\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~4.}}
\emph{Physical Model Validation:
The SCAPS-1D simulations use fixed FeB parameters
(binding energy, migration energy, and pre-exponential factors).
Yet, these parameters vary widely in literature (0.55–0.69 eV for migration energy).
Without sensitivity analysis or error quantification,
the generated synthetic dataset may not reflect realistic kinetics.
Validation against first-principles or experimental benchmarks would strengthen the study.}


\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


Allow us to say a few words  in favor of GaAs and 6H-SiC.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~5.}}
\emph{Regression and Feature Interpretation:
Although multiple regressors (SVR, XGB, DNN, RF, GB) are compared,
no insight is given into the learned features or their physical correlation with iron concentration.
Incorporating explainable AI techniques (e.g., SHAP, PCA loading analysis)
would add interpretability to what the CNN features represent.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


Allow us to say a few words  in favor of GaAs and 6H-SiC.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~6.}}
\emph{Post-Hoc Correction:
The quadratic correction (Eq. 10) is an empirical adjustment
that artificially improves metrics but lacks theoretical justification.
The authors should either
(i) replace it with a physics-informed calibration (e.g., temperature or diffusion based scaling)
or (ii) clearly acknowledge its heuristic nature and limitations.}


\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


Allow us to say a few words  in favor of GaAs and 6H-SiC.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Major Comment~7.}}
\emph{Statistical Reporting:
The reported MSE, MAPE, and R$^2$ values are given without variance or confidence intervals.
Given the small datasets, reporting mean ± standard deviation across multiple random splits
would be essential to establish statistical robustness.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


Allow us to say a few words  in favor of GaAs and 6H-SiC.

\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~1.}}
\emph{The introduction is overly broad;
it should focus more on ML for microscopic defects
rather than general PV or macro-defect analysis.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}

The body of work specifically focused on applying ML to microscopic defect analysis remains relatively limited.
However, we conducted a detailed review of the publications cited in the initial manuscript draft and
carried out an extensive supplementary literature search.
 As a result, it has been established that
existing applications of ML in microscopic defect characterization can be broadly categorized into several distinct approaches.
One such approach focuses on enhancing conventional defect-analysis techniques through the integration of
Artificial Intelligence methods for processing and interpreting the resulting experimental signals.

For example, Buratti \emph{et al.} \cite{Buratti2020a} employed regression algorithms, including Random Forest (RF), Gradient Boosting (GB), and Deep Neural Networks (DNN),
to analyze dependencies derived from temperature- and injection-dependent lifetime spectroscopy (TIDLS).
They trained the models on more than one million simulated curves, which enabled
accurate estimation of
silicon defect energy levels and carrier capture cross-sections.
In addition, unlike the conventional fitting of signals with the Shockley–Read–Hall equation,
their approach can also predict the energy level position at half of the bandgap.
An extension of this approach was presented in \cite{Buratti2022}, where the methodology incorporated a
Convolutional Neural Network (CNN) to analyse images derived from a family of lifetime curves measured at different temperatures,
in addition to applying a RF model to the standard TIDLS signal.
In that study, the CNN was used both to perform the classification of the half-bandgap position of the energy level
and to extract features, which were subsequently used by the RF.
As in the earlier work, the models were trained on a dataset consisting of several hundred thousand synthetic samples.
An alternative TIDLS signal processing strategy was also investigated by Wang \emph{et al.} \cite{Wang2024a},
who used CNNs to analyse one-dimensional signals and thereby extract parameters associated with two-energy-level defects in silicon.
Machine-learning methods are also employed for the analysis of Raman spectra \cite{Chia2024}.
In this study, the spectra of electron-irradiated GaAs were examined using linear discriminant analysis models.
These models were trained on 6,000 experimentally acquired spectra, enabling the identification of radiation-induced defects.



An alternative approach is based on determining defect parameters by analysing the characteristics of devices, primarily solar cells,
that are directly affected by such defects.
For silicon solar cells, for example, a methodology has been proposed to estimate the concentration of contaminant impurities
from the magnitude of the ideality factor obtained from current–voltage ($I$–$V$) characteristics \cite{Olikh2022PPV}
or from variations in photovoltaic conversion parameters \cite{Olikh2025SE}.
In both studies, classical regression algorithms (DNN, RF, Support Vector Regression (SVR), and GB) were employed.
The numerical values of parameters extracted from the $I$–$V$ characteristics served as input features,
and the models were trained on tens of thousands of current–voltage curves simulated under different defect parameters.
A closely related approach was presented by Haidari \emph{et al.} \cite{Haidari2025},
who used thirteen parameters extracted from the $I$–$V$ curves of CIGS solar cells as inputs to a DNN to predict the spatial distribution and concentration of six bulk and surface defects.
The inverse problem, namely the determination of photovoltaic conversion parameters based on predefined defect concentrations,
was examined by \emph{Kim et al.} \cite{Kim2023a} for perovskite solar cells.
In that study, RF, XGBoost,
Linear Regression, and Multilayer Perceptron algorithms were evaluated,
and the RF model delivered the highest performance.
In all four studies mentioned above, the SCAPS-1D simulation tool was consistently used
to generate the synthetic $I$–$V$ characteristics that formed the training datasets.



Beyond the detection and characterization of defects in actual devices,
a distinct research direction focuses on accelerating and improving density functional theory (DFT)
and molecular dynamics (MD) calculations of defect parameters.
For example, several studies have demonstrated the use of Graph Neural Networks, trained on DFT-calculated data,
to estimate vacancy formation energies \cite{Choudhary2023, Kumagai2025}
and to evaluate the electronic structure of charged defects in GaAs \cite{Ma2025}.
Graph Convolutional Networks have also been applied to MD-generated datasets for predicting
vacancy diffusion paths in high-entropy alloys \cite{Reimer2025} and intrinsic defects in perovskites \cite{Tyagi2025}.
In addition, DFT datasets have been integrated with ML methods to identify formation enthalpies
and ionization energies of impurity defects \cite{MannodiKanakkithodi2022} and
to determine the equilibrium configurations of defects in emerging materials \cite{MosqueraLois2024}.


The relevant information has been incorporated into the Introduction section (pages 1–2, paragraphs three through six).


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~2.}}
\emph{Some typographical errors exist (e.g., ``where where'' in Eq. 1).
Please proofread carefully.}


\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We carefully reviewed the manuscript and corrected multiple typographical errors.
Namely:

\noindent
-
changed phrase ``Standard approaches to solving such problems involve the use of Fourier or wavelet transforms, and last were applied in this study''
to  ``Standard approaches to solving such problems involve the use of Fourier or wavelet transforms, and \textcolor[rgb]{1.00,0.07,0.00}{the latter}
were applied in this study'' on page~2;

\noindent
- changed ``where where'' to ``where'' after Eq.~(1);

\noindent
- changed ``A is the constant'' to ``A is the pre-exponential constant'' after Eq.~(3);

\noindent
- changed phase ``Panels (b) and (c) show the wavelet spectrograms corresponding to the curves with filled squares and open circles, respectively''
to ``Panels (b) and (c) show the wavelet spectrograms corresponding to the curves with \textcolor[rgb]{1.00,0.07,0.00}{open}  squares
and \textcolor[rgb]{1.00,0.07,0.00}{filled} circles, respectively''
in the caption of Fig~3;

\noindent
- a sentence was added to clarify the applicability of the formula for the median absolute percentage error
``Eq.~(8) implies that  $\mathtt{MAPE}_i$ must be arranged in order of magnitude; '' after Eq.~(8)


\noindent
etc.

\noindent
We hope that these revisions have resolved the issue as thoroughly as possible.




\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~3.}}
\emph{Figures should include axis units, consistent color scales, and indicate whether values
are in linear or logarithmic scale.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}

We thank the Reviewer for identifying the shortcomings in the figures.
Axes, units of measurement, and color scales have been added to Figures~2b, 2c, 3b, and 3c.
The units of measurement (\%) corresponding to the MAPE and MedAPE values have also been included next to the color scale labels,
as shown in Figures 5, 6, 7, 9, and 10.
The mutual arrangement of the ticks and tick labels in all figures enables unambiguous identification of the scale type.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~4.}}
\emph{The Supplementary Figures (S1–S10) are repeatedly referenced
but insufficiently summarized in the main text.
A concise overview table would be helpful.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


Allow us to say a few words  in favor of GaAs and 6H-SiC.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~5.}}
\emph{The data availability statement (``upon reasonable request'')
should be replaced with
a public repository link for transparency.}


\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}

We have made the data, including simulated and experimentally measured short-circuit current kinetic dependencies
as well as wavelet spectrogram images, together with the trained models, available in a public repository
(\url{https://github.com/olegolikh/CV_Fe_SiSC.git}).

\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~6.}}
\emph{A comparison with simpler ML baselines
(e.g., direct regression on ISC(t) data without wavelet transformation) would
contextualize the improvement due to CV-based transfer learning.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}

Following the Reviewer’s suggestion, CNN models were designed
that directly process the kinetic dependencies of the short-circuit current
to predict iron concentration.
The 1D-CNN model used in this study comprises two one-dimensional convolutional layers
followed by global average pooling and three fully connected layers.
The first convolutional layer has a kernel size of three,
a padding of one, and eight output channels.
The second convolutional layer also uses a kernel size of three and a padding of one,
but with sixteen output channels.
The resulting feature maps are aggregated using a global average pooling layer.
The aggregated feature vector is then passed through a fully connected layer with 64 neurons,
followed by a second fully connected layer with 32 neurons.
The network output is generated by a final fully connected layer with a single neuron.
During network tuning, the configuration of batch normalization and regularization in the convolutional layers,
dropout between fully connected layers, activation functions, and weight initialization was performed.
The models were trained and tested on the same dataset,
comprising both artificial and experimental data, from which the wavelet spectrograms were generated.
The resulting performance metrics are presented in the \tref{tab1DCNN}.

\begin{table*}
%\centering
\caption{Summary of 1D-CNN model performance metrics \label{tab1DCNN}}
\noindent
\makebox[\textwidth][c]{
\begin{tabular}{ccccccc}
\br
\makecell{Training Data\\Type}  &   \makecell{Evaluation\\ Dataset} &   MSE ($10^{-3}$) &   $R^2$ &   MAPE (\%)&   MedAPE (\%) &\makecell{ Reference \\(CV-based Models)$^*$}\\
\mr
Simulated & Train       & $31\pm5$ & $0.89\pm0.02$ & $35\pm5$ & $32\pm2$ & Fig.5, Fig.S2  \\
 & Test       & $30\pm5$ & $0.90\pm0.04$ & $35\pm5$ & $32\pm3$ & Fig.6, Fig.S3  \\
 & \makecell{Experimental, without \\post-hoc calibration}       & $530\pm70$ & $<0.1$ & $480\pm60$ & $400\pm20$ & Fig.7(a,b), Fig.S4  \\
& \makecell{Experimental, with \\post-hoc calibration}       & $250\pm50$ & $0.6\pm0.1$ & $50\pm10$ & $44\pm8$ & Fig.7(c,d), Fig.S5  \\
Experimental & Train       & $27\pm7$ & $0.2\pm0.1$ & $33\pm6$ & $26\pm8$ & Fig.9, Fig.S7  \\
 & Test       & $30\pm10$ & $<0.1$ & $40\pm10$ & $30\pm15$ & Fig.10, Fig.S8  \\
\mr
\multicolumn{7}{p{\dimexpr\linewidth-2\tabcolsep\relax}}{
$^*$\emph{ The column indicates the figures in which performance metrics obtained for CV-based models under comparable conditions are reported.}
}\\
\br
\end{tabular}
}
\end{table*}



\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Minor Comment~7.}}
\emph{References [6], [35], [38] should be verified for year and page accuracy.
Some reference formatting inconsistencies (journal abbreviations, italics) should be corrected.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We have thoroughly verified all references, with particular attention given
to the citations specifically requested by the Reviewer.
Several images containing the references included in the manuscript,
as well as screenshots of the corresponding publisher pages, are attached --- see \Fref{FigR1c7}.

In general, the reference list is generated using .bib files downloaded directly from the publishers’ websites.
The final formatting of the references is applied automatically according to the IOPscience style guidelines for manuscript preparation.
Journal abbreviations follow the options provided by JabRef 5.9.
We therefore trust that the final list of literature sources is formatted correctly.

\begin{figure*}
\includegraphics[width=0.55\textwidth]{R2Cm7FigA}
\includegraphics[width=0.45\textwidth]{R2Cm7FigB}
\includegraphics[width=0.9\textwidth]{R2Cm7FigC}
\caption{\label{FigR1c7}
Three images are provided to illustrate the correctness of the references.
The upper part of each image contains an excerpt from the bibliography,
and the lower part shows a screenshot of the corresponding publisher page.
}
\end{figure*}


\subsection*{Response to Reviewer \#2 }
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Comment~1.}}
\emph{It is additionally essential to examine temperatures between 270 to 350 kelvin.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


To our shame, the reviewer is correct about some fog in Results and discussion.
We hopefully rephrased the section to add sunlight.



\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Comment~2.}}
\emph{You should compare and review your manuscript with
other new articles such as ``Novel Design of Multi-Layer Cubic Nanoparticles for Achieving Efficient Thin-Film Perovskite Solar Cells''}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We have expanded the Introduction section, as detailed in our responses to Minor Comment~1 and Major Comment~1 from Reviewer 1.
In particular, the article mentioned in Reviewer 2's comment is now cited as Reference [38] in the revised manuscript.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Comment~3.}}
\emph{Put the solar cell parameters in a table with references.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We added Table~1 to the revised manuscript (page~5).
This table summarizes the parameters of the solar cell, silicon, and defect states at the temperature used in the main calculations.


\vspace{1cm}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{Comment~4.}}
\emph{Actually, all solar cells have Rs and Rsh values.
By investigating parasitic losses on cell performance, the article could be made more interesting.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}
We fully agree with the Reviewer that, for real solar cells, it is essential to consider the influence of series and shunt resistances on the efficiency of photovoltaic conversion.
In particular, the presence of these resistances reduces the short-circuit current.
In an ideal case, the short-circuit current $I_\mathtt{SC}$ is equal to the photogenerated current $I_\mathtt{ph}$:
\begin{equation*}
  I_\mathtt{SC} = I_\mathtt{ph}\,.
\end{equation*}
In the presence of resistances, within the single-diode model approximation
\begin{equation*}
  I_\mathtt{SC} \approx I_\mathtt{ph}\frac{R_\mathtt{sh}}{R_\mathtt{sh}+R_\mathtt{s}}\,.
\end{equation*}
However, when FeB pairs are restored, the values of $R_\mathtt{sh}$ and $R_\mathtt{s}$  remain unchanged.
Therefore, the presence of parasitic resistances will effectively scale the dependence $I_\mathtt{SC}(t)$
by a constant factor only.
In this case, the resulting wavelet spectrogram remains unaffected.
As an example, \Fref{Fig4} presents the spectrograms obtained for the kinetic dependencies of the short-circuit current before
and after normalization to the initial current value.
It can be seen that normalization affects the amplitude of the continuous wavelet transform,
but this change is proportional across all frequency and time values.
As a result, the graphical appearance of the spectrogram remains unchanged,
and computer vision models extract the same features regardless of normalization
(and, consequently, regardless of the presence of parasitic resistance).

\begin{figure*}
\includegraphics[width=0.4\textwidth]{R2C4FigA}
\includegraphics[width=0.4\textwidth]{R2C4FigB}
\caption{\label{Fig4}
Wavelet spectrograms corresponding to the simulated short-circuit curves for a solar cell with
$N_\mathtt{Fe}=10^{13}$~cm$^{-3}$, obtained before (left) and after (right) normalization.
}
\end{figure*}

Thus, the method proposed in this work for estimating the concentration of impurity iron is
inherently resistant to the presence of series and shunt resistances.
The corresponding information has been added to the manuscript in the final paragraph preceding the Conclusion section.
We are grateful to the Reviewer for highlighting this additional advantage of the proposed approach.

A direct investigation of the influence of parasitic losses on cell performance was not the objective of this study.

\subsection*{Response to EDITOR REPORT}
\noindent
\textcolor[rgb]{0.00,0.50,1.00}{\textbf{REPORT.}}
\emph{We have found that your manuscript contains text which appears to have been replicated from the following published articles:}

\emph{www.sciencedirect.com/science/article/abs/pii/S0038092X25005171?via\%3Dihub}

\emph{Please reduce the level of overlap in your revised manuscript by rewriting the appropriate sections.}

\noindent
\textcolor[rgb]{0.51,0.00,0.00}{\textbf{Reply:}}


First, we apologize for the observed similarities.
The cited article is our own and also addresses the determination of iron concentration in silicon solar cells.
However, the approaches used in the cited work and in the present study are fundamentally different.
In the former, regression models are employed that utilize changes in photoelectric parameters during the decay of FeB pairs,
whereas in the present manuscript, the primary approach involves converting the kinetic dependencies of the short-circuit current
into images and extracting features using computer vision models.
Nevertheless, both studies use similar solar cell models, apply standard regression algorithms and metrics,
and perform testing on experimental samples from the same batch. This explains certain similarities in wording.

We have revised the relevant sections and reduced the extent of overlap.


\cite{Wijaranakula}


\section*{References}

\bibliographystyle{iopart-num}
\bibliography{olikh}

\end{document}

